{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Zadanie1_lab10.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPnMq/ndiJFe1XkaBt5mZMh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/76027/prir/blob/main/Lab10/Zadanie1_lab10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GKa6hyRxikZ"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from math import *\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "class M_prostokatow:\r\n",
        "    def __init__(self,a,b,n):\r\n",
        "        self.a = a\r\n",
        "        self.b = b\r\n",
        "        self.n = n\r\n",
        "\r\n",
        "    def f(self,x):\r\n",
        "        return 2*x\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    def oblicz(self):\r\n",
        "\r\n",
        "        s = 0\r\n",
        "        h = (self.b - self.a) / self.n\r\n",
        "        for i in range(1,self.n):\r\n",
        "            s += self.f(self.a) * h\r\n",
        "            self.a += h\r\n",
        "        return s\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class M_trapezow:\r\n",
        "    def __init__(self, a, b, n):\r\n",
        "        self.a = a\r\n",
        "        self.b = b\r\n",
        "        self.n = n\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    def f(self,x):\r\n",
        "        return 2*x\r\n",
        "\r\n",
        "\r\n",
        "    def oblicz(self):\r\n",
        "        s = 0\r\n",
        "        h = (self.b - self.a) / self.n\r\n",
        "        for i in range(1,self.n+1):\r\n",
        "            s += ((self.f(self.a) + self.f(self.a+h)) * h) / 2\r\n",
        "            self.a += h\r\n",
        "        return s\r\n",
        "\r\n",
        "class M_Simpsona():\r\n",
        "    def __init__(self, a, b, n):\r\n",
        "        self.n = n\r\n",
        "        self.a = a\r\n",
        "        self.b = b\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "    def f(self, x):\r\n",
        "        return 2*x\r\n",
        "\r\n",
        "    def oblicz(self):\r\n",
        "        s = 0\r\n",
        "        st = 0\r\n",
        "        h = (self.b - self.a) / self.n\r\n",
        "        for i in range(1,self.n+1):\r\n",
        "            x = self.a + i * h\r\n",
        "            st += self.f(x - h / 2)\r\n",
        "            if (i < self.n):\r\n",
        "                s += self.f(x)\r\n",
        "\r\n",
        "        s = h / 6 * (self.f(self.a) + self.f(self.b) + 2 * s + 4 * st)\r\n",
        "        return s"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDdEfcKpx--K"
      },
      "source": [
        "Tworzę klasy z z zaimplemontowanymi metodami trapezów, prostokątów i Simpsona,obliczające pole pod całką 2*x"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8SxbriFx7k9",
        "outputId": "9b1c72c5-30f8-4a14-9dbd-f398de1e0bde"
      },
      "source": [
        "x = np.arange(1,10,1)\r\n",
        "x = np.asarray(x)\r\n",
        "print(x)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 2 3 4 5 6 7 8 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZA2GgSv2sTP"
      },
      "source": [
        "Tworzę macierz elementów z przedziału od 1 do 10 z krokiem 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02p7--Mv3F3W",
        "outputId": "f6cbf63b-9699-4f70-fa30-c3a69c1c94bc"
      },
      "source": [
        "print(\"Metoda prostokatow\")\r\n",
        "met_pro = [M_prostokatow(i,i+1,3000).oblicz() for i in x]\r\n",
        "met_pro = np.asarray(met_pro)\r\n",
        "print(met_pro)\r\n",
        "\r\n",
        "print(\"Metoda trapezow\")\r\n",
        "met_tra = [M_trapezow(i,i+1,3000).oblicz() for i in x]\r\n",
        "met_tra = np.asarray(met_tra)\r\n",
        "print(met_tra)\r\n",
        "\r\n",
        "print(\"Metoda Simpsona\")\r\n",
        "met_sim = [M_Simpsona(i,i+1,3000).oblicz() for i in x]\r\n",
        "met_sim = np.asarray(met_sim)\r\n",
        "print(met_sim)\r\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Metoda prostokatow\n",
            "[ 2.99833356  4.99766689  6.99700022  8.99633356 10.99566689 12.99500022\n",
            " 14.99433356 16.99366689 18.99300022]\n",
            "Metoda trapezow\n",
            "[ 3.  5.  7.  9. 11. 13. 15. 17. 19.]\n",
            "Metoda Simpsona\n",
            "[ 3.  5.  7.  9. 11. 13. 15. 17. 19.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlSmOdjN7KdO"
      },
      "source": [
        "Wypisuje wyniki z działania funkcji w przedziałach [1:2] .... [9:10] przy 3000 iteracji\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4yBgnI-7c2O"
      },
      "source": [
        "model_p = tf.keras.models.Sequential([\r\n",
        "  tf.keras.layers.Dense(1, input_shape=(1, )),\r\n",
        "  # tf.keras.layers.Dense(3,activation='relu'),\r\n",
        "  # tf.keras.layers.Dense(4,activation='sigmoid'),\r\n",
        "  # tf.keras.layers.Dense(3,activation='relu'),\r\n",
        "  tf.keras.layers.Dense(1)\r\n",
        "])\r\n",
        "\r\n",
        "model_t = tf.keras.models.Sequential([\r\n",
        "  tf.keras.layers.Dense(1, input_shape=(1, )),\r\n",
        "  # tf.keras.layers.Dense(3,activation='relu'),\r\n",
        "  # tf.keras.layers.Dense(4,activation='sigmoid'),\r\n",
        "  # tf.keras.layers.Dense(3,activation='relu'),\r\n",
        "  tf.keras.layers.Dense(1)\r\n",
        "])\r\n",
        "\r\n",
        "model_S = tf.keras.models.Sequential([\r\n",
        "  tf.keras.layers.Dense(1, input_shape=(1, )),\r\n",
        "  # tf.keras.layers.Dense(3,activation='relu'),\r\n",
        "  # tf.keras.layers.Dense(4,activation='sigmoid'),\r\n",
        "  # tf.keras.layers.Dense(3,activation='relu'),\r\n",
        "  tf.keras.layers.Dense(1)\r\n",
        "])\r\n",
        "\r\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzn7HDQbmOr4"
      },
      "source": [
        "Tworzę modele dla każdej metody"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "839QOuZUmPlf"
      },
      "source": [
        "\r\n",
        "model_p.compile(optimizer=tf.optimizers.Adam(learning_rate=0.1), loss='mean_squared_error')\r\n",
        "\r\n",
        "\r\n",
        "model_t.compile(optimizer=tf.optimizers.Adam(learning_rate=0.1), loss='mean_squared_error')\r\n",
        "\r\n",
        "model_S.compile(optimizer=tf.optimizers.Adam(learning_rate=0.1), loss='mean_squared_error')"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgFQdmI5X934"
      },
      "source": [
        "Porównuję działanie dwóch optymizatorów, optymizator adam z rating rate =0.1, optymizator mean_squared_error wydaje się dokładniejszy w tym przykładzie.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DMmf5iQZYSQX",
        "outputId": "412f86ed-dd4a-4de7-f997-f5a73ec60410"
      },
      "source": [
        "model_p.fit(x,met_pro,epochs = 50)\r\n",
        "\r\n",
        "model_t.fit(x,met_tra,epochs = 50)\r\n",
        "\r\n",
        "model_S.fit(x,met_sim,epochs = 50)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 9.3353\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7020\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.3089\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7740\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4607\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1350\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7434\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.5775\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2454\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6327\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.2265\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5571\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.4510\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0169\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5097\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1838\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.1676\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3944\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6475\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7225\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5732\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3148\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1120\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0619\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1477\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2731\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.3374\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2978\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1840\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0686\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0169\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0450\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.1123\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1559\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1402\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0800\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0215\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0021\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0244\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0602\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0772\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0627\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0300\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0044\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0023\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0197\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0374\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0391\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0247\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0075\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 234ms/step - loss: 5.6978\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.4141\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.6941\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2589\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.5543\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7270\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6594\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0824\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.2555\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.8302\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1757\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 1.0069\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5342\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1365\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0424\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2195\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.4616\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5694\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4775\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.2636\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0726\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0164\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1012\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2288\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2813\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.2189\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0994\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0149\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0144\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0747\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.1321\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.1372\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0893\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0288\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2696e-04\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0182\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0559\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0747\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0582\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0237\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0014\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0061\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0265\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0401\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0344\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0159\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0019\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0029\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0143\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0224\n",
            "Epoch 1/50\n",
            "1/1 [==============================] - 0s 265ms/step - loss: nan\n",
            "Epoch 2/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 3/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 4/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 5/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: nan\n",
            "Epoch 6/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 7/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 8/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 9/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 10/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 11/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 12/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 13/50\n",
            "1/1 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 14/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 15/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 16/50\n",
            "1/1 [==============================] - 0s 9ms/step - loss: nan\n",
            "Epoch 17/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 18/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 19/50\n",
            "1/1 [==============================] - 0s 8ms/step - loss: nan\n",
            "Epoch 20/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 21/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 22/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 23/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 24/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 25/50\n",
            "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 26/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 27/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 28/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 29/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 30/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 31/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 32/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 33/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 34/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 35/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 36/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 37/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 38/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 39/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 40/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 41/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 42/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 43/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 44/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 45/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 46/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 47/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 48/50\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 49/50\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 50/50\n",
            "1/1 [==============================] - 0s 3ms/step - loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb61e02fa20>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glEYs-dy0LGd"
      },
      "source": [
        "Trenuję modele,po 50 epok"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWxTX7QU021k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46a94276-de9d-40be-a483-8b1a30550400"
      },
      "source": [
        "print(\"Przewidywania metody prostokatow\")\r\n",
        "p = model_p.predict(x)\r\n",
        "print(p.flatten())\r\n",
        "print(\"######Wynik z metody prostokatow#######\")\r\n",
        "print(met_pro)\r\n",
        "print(\"###################\")\r\n",
        "srednia = 0\r\n",
        "for i in range(len(x)):\r\n",
        "  \r\n",
        "  srednia += abs(p[i]-met_pro[i])\r\n",
        "  print(\"Roznica miedzy wynikami: \",abs(p[i]-met_pro[i]))\r\n",
        "\r\n",
        "srednia = srednia/len(x)\r\n",
        "print(\"Srednia arytmetyczna bledow: \",srednia)\r\n"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Przewidywania metody prostokatow\n",
            "WARNING:tensorflow:9 out of the last 15 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb61e3c5bf8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[ 2.9342332  4.944697   6.955161   8.965625  10.976088  12.986552\n",
            " 14.997015  17.00748   19.017944 ]\n",
            "######Wynik z metody prostokatow#######\n",
            "[ 2.99833356  4.99766689  6.99700022  8.99633356 10.99566689 12.99500022\n",
            " 14.99433356 16.99366689 18.99300022]\n",
            "###################\n",
            "Roznica miedzy wynikami:  [0.06410027]\n",
            "Roznica miedzy wynikami:  [0.05296993]\n",
            "Roznica miedzy wynikami:  [0.04183912]\n",
            "Roznica miedzy wynikami:  [0.03070831]\n",
            "Roznica miedzy wynikami:  [0.01957893]\n",
            "Roznica miedzy wynikami:  [0.00844765]\n",
            "Roznica miedzy wynikami:  [0.00268173]\n",
            "Roznica miedzy wynikami:  [0.01381302]\n",
            "Roznica miedzy wynikami:  [0.02494431]\n",
            "Srednia arytmetyczna bledow:  [0.02878703]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9nMDsrH5Db8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95e81513-7e62-4033-dae7-2b0f9a1212cf"
      },
      "source": [
        "print(\"Przewidywania metody trapezow\")\r\n",
        "t = model_t.predict(x)\r\n",
        "print(t.flatten())\r\n",
        "print(\"######Wynik z metody trapezow#######\")\r\n",
        "print(met_tra)\r\n",
        "print(\"###################\")\r\n",
        "srednia = 0\r\n",
        "for i in range(len(x)):\r\n",
        "  \r\n",
        "  srednia += abs(t[i]-met_tra[i])\r\n",
        "  print(\"Roznica miedzy wynikami: \",abs(p[i]-met_tra[i]))\r\n",
        "\r\n",
        "srednia = srednia/len(x)\r\n",
        "print(\"Srednia arytmetyczna bledow: \",srednia)\r\n"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Przewidywania metody trapezow\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb61e66b840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "[ 2.9916205  5.0219812  7.0523424  9.082703  11.113063  13.143424\n",
            " 15.173783  17.204145  19.234507 ]\n",
            "######Wynik z metody trapezow#######\n",
            "[ 3.  5.  7.  9. 11. 13. 15. 17. 19.]\n",
            "###################\n",
            "Roznica miedzy wynikami:  [0.06576681]\n",
            "Roznica miedzy wynikami:  [0.0553031]\n",
            "Roznica miedzy wynikami:  [0.04483891]\n",
            "Roznica miedzy wynikami:  [0.03437519]\n",
            "Roznica miedzy wynikami:  [0.02391243]\n",
            "Roznica miedzy wynikami:  [0.01344776]\n",
            "Roznica miedzy wynikami:  [0.002985]\n",
            "Roznica miedzy wynikami:  [0.00748062]\n",
            "Roznica miedzy wynikami:  [0.01794434]\n",
            "Srednia arytmetyczna bledow:  [0.11492533]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwnI2x9s5Gp0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e948ece8-9fb0-4fc7-9a86-2ddd8e54d9e6"
      },
      "source": [
        "print(\"Przewidywania metody Simpsona\")\r\n",
        "s = model_S.predict(x)\r\n",
        "print(s.flatten())\r\n",
        "print(\"######Wynik z metody Simpsona#######\")\r\n",
        "print(met_sim)\r\n",
        "print(\"###################\")\r\n",
        "srednia = 0\r\n",
        "for i in range(len(x)):\r\n",
        "  \r\n",
        "  srednia += abs(t[i]-met_sim[i])\r\n",
        "  print(\"Roznica miedzy wynikami: \",abs(p[i]-met_sim[i]))\r\n",
        "\r\n",
        "srednia = srednia/len(x)\r\n",
        "print(\"Srednia arytmetyczna bledow: \",srednia)\r\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Przewidywania metody Simpsona\n",
            "[nan nan nan nan nan nan nan nan nan]\n",
            "######Wynik z metody Simpsona#######\n",
            "[ 3.  5.  7.  9. 11. 13. 15. 17. 19.]\n",
            "###################\n",
            "Roznica miedzy wynikami:  [0.06576681]\n",
            "Roznica miedzy wynikami:  [0.0553031]\n",
            "Roznica miedzy wynikami:  [0.04483891]\n",
            "Roznica miedzy wynikami:  [0.03437519]\n",
            "Roznica miedzy wynikami:  [0.02391243]\n",
            "Roznica miedzy wynikami:  [0.01344776]\n",
            "Roznica miedzy wynikami:  [0.002985]\n",
            "Roznica miedzy wynikami:  [0.00748062]\n",
            "Roznica miedzy wynikami:  [0.01794434]\n",
            "Srednia arytmetyczna bledow:  [0.11492533]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjoAjk1oUdZP"
      },
      "source": [
        "Wypisuje wyniki i roznice miedzy przywidywanymi wynikami a wynikami funkcji\r\n",
        "Poniżej dla porówaniania trenuję ponownie model dla metody prostokatokatow,w zależności od tego jaki learning rate wybiore wyniki mogą być dokładniejsze albo występuje przetrenowanie modelu"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOckm1KhUvUg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "129157fc-102b-41fe-e1a7-2e7d6e18935e"
      },
      "source": [
        "model_p.fit(x,met_pro,epochs = 100)\r\n",
        "\r\n",
        "model_t.fit(x,met_tra,epochs = 100)\r\n",
        "\r\n",
        "model_S.fit(x,met_sim,epochs = 100)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0012\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0080\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0187\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0228\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0169\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0071\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0017\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0039\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0099\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0129\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0101\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0044\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0011\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0023\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0055\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0070\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0053\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.0021\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.3022e-04\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0013\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0031\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0037\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0024\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9264e-04\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.5920e-05\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3574e-04\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 0.0018\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 2ms/step - loss: 0.0018\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.6548e-04\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2960e-04\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.5729e-05\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8075e-04\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.0011\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.8157e-04\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1988e-04\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3626e-05\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1831e-04\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.7015e-04\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.3934e-04\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7055e-04\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.6384e-05\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2300e-05\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6987e-04\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9881e-04\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0526e-04\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1193e-04\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2937e-05\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1714e-04\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2170e-04\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0725e-04\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.5871e-05\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8035e-05\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.3903e-05\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1250e-04\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2502e-04\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 6.6853e-05\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0069e-05\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3364e-05\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.4825e-05\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.2001e-05\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.3333e-05\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.7632e-06\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7022e-06\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.8226e-05\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.2426e-05\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8153e-05\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 5.7536e-06\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2326e-06\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6682e-05\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6284e-05\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8488e-05\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 4.8554e-06\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2996e-06\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0857e-05\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6568e-05\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1634e-05\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.2926e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8867e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.0531e-06\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0082e-05\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6389e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6324e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1729e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3901e-06\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.8078e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3598e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.1288e-07\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9469e-07\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7376e-06\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2469e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5360e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3883e-08\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.6369e-07\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8111e-06\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8192e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.6933e-07\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6772e-08\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7918e-07\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2550e-06\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0183e-06\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0189\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0082\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0600e-04\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0026\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0092\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.0128\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0096\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.0034\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1040e-04\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0024\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0061\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.0070\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0041\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.2285e-04\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1280e-04\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0023\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0040\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0033\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2268e-05\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.6229e-04\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0020\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.0022\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0012\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4395e-04\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5166e-04\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.1647e-04\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.0013\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.2413e-04\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2006e-04\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3356e-05\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3149e-04\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.8788e-04\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3817e-04\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0589e-04\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7549e-05\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1743e-04\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.5931e-04\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1004e-04\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5217e-04\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1956e-05\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1627e-04\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6878e-04\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4927e-04\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.3791e-05\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1333e-06\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.7361e-05\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5956e-04\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4547e-04\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.0462e-05\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.1128e-07\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.3275e-05\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.7198e-05\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.2346e-05\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: 2.3797e-05\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.4664e-07\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.1667e-05\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0835e-05\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.5111e-05\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.7992e-06\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4968e-06\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4807e-05\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8080e-05\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3174e-05\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2275e-06\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.4127e-06\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9199e-05\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2716e-05\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0391e-05\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.6289e-07\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3966e-06\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3822e-05\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2190e-05\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5346e-06\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.5244e-07\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4112e-06\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.9726e-06\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.4956e-06\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.1332e-07\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0555e-06\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.6573e-06\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.0773e-06\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8496e-06\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8970e-09\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6686e-06\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4262e-06\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3685e-06\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4212e-07\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3974e-07\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7966e-06\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0635e-06\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.9152e-07\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.3104e-08\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.2393e-07\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4008e-06\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.2191e-07\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2744e-07\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0273e-07\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.8081e-07\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.8836e-07\n",
            "Epoch 1/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: nan\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: nan\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: nan\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: nan\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: nan\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: nan\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 18ms/step - loss: nan\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: nan\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 15ms/step - loss: nan\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: nan\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: nan\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: nan\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 8ms/step - loss: nan\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: nan\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb60c3fa3c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDSzD9KzU28J"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1tFSr10VCuP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55f29863-68c8-45f5-f910-484ede3f55cf"
      },
      "source": [
        "print(\"Przewidywania metody prostokatow\")\r\n",
        "p = model_p.predict(x)\r\n",
        "print(p.flatten())\r\n",
        "print(\"######Wynik z metody prostokatow#######\")\r\n",
        "print(met_pro)\r\n",
        "print(\"###################\")\r\n",
        "srednia = 0\r\n",
        "for i in range(len(x)):\r\n",
        "  \r\n",
        "  srednia += abs(p[i]-met_pro[i])\r\n",
        "  print(\"Roznica miedzy wynikami: \",abs(p[i]-met_pro[i]))\r\n",
        "\r\n",
        "srednia = srednia/len(x)\r\n",
        "print(\"Srednia arytmetyczna bledow: \",srednia)\r\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Przewidywania metody prostokatow\n",
            "[ 2.998693   4.9978576  6.9970217  8.996187  10.995352  12.994515\n",
            " 14.99368   16.992846  18.99201  ]\n",
            "######Wynik z metody prostokatow#######\n",
            "[ 2.99833356  4.99766689  6.99700022  8.99633356 10.99566689 12.99500022\n",
            " 14.99433356 16.99366689 18.99300022]\n",
            "###################\n",
            "Roznica miedzy wynikami:  [0.00035954]\n",
            "Roznica miedzy wynikami:  [0.00019073]\n",
            "Roznica miedzy wynikami:  [2.1457672e-05]\n",
            "Roznica miedzy wynikami:  [0.00014591]\n",
            "Roznica miedzy wynikami:  [0.00031471]\n",
            "Roznica miedzy wynikami:  [0.00048447]\n",
            "Roznica miedzy wynikami:  [0.00065327]\n",
            "Roznica miedzy wynikami:  [0.00082207]\n",
            "Roznica miedzy wynikami:  [0.00098991]\n",
            "Srednia arytmetyczna bledow:  [0.00044245]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpuBRzc5j231"
      },
      "source": [
        "Model jest dokładny w zbiorze treningowym,poniżej sprawdzę go poza zbiorem"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_zl_og6ucCh",
        "outputId": "9364ae5a-a244-4b9e-9ed9-39531781ad70"
      },
      "source": [
        "print(\"Wynik metody w przedziale (11;12): \",M_prostokatow(11,12,3000).oblicz())\r\n",
        "print(\"Wynik działania modelu: \",float(model_p.predict((11,))))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wynik metody w przedziale (11;12):  22.99166688889011\n",
            "Wynik działania modelu:  22.990341186523438\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}